{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_excel(file):\n",
    "    df = pd.read_excel(file)\n",
    "    return df\n",
    "\n",
    "def read_files_and_coordinates(files_directory, coordinates_filepath):\n",
    "    dfs = []\n",
    "    filenames = []\n",
    "    for file in os.listdir(files_directory):\n",
    "        if file.endswith(\".xlsx\"):\n",
    "            df = read_excel(files_directory + file)\n",
    "            print(\"Reading file: \", file, \" at index: \", len(dfs))\n",
    "            dfs.append(df)\n",
    "            filenames.append(file)\n",
    "    \n",
    "    coordinates_df = pd.read_excel(coordinates_filepath)\n",
    "\n",
    "    # store the values from Coordinates column from coordinates_df to a 2d array\n",
    "    coordinates = []\n",
    "    for i in range(len(coordinates_df)):\n",
    "        coordinates.append(coordinates_df.iloc[i, 1].split(','))\n",
    "        for j in range(len(coordinates[i])):\n",
    "            coordinates[i][j] = float(coordinates[i][j])\n",
    "\n",
    "    return dfs, coordinates, filenames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files_directory = \"../../Data/Processed data/\"\n",
    "# coordinates_filepath = \"../../Data/coordinates.xlsx\"\n",
    "# dfs, coordinates, filenames = read_files_and_coordinates(files_directory, coordinates_filepath)\n",
    "# print(\"Data read successfully\")\n",
    "# print(\"Number of files read: \", len(dfs))\n",
    "# print(\"Number of coordinates read: \", len(coordinates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dfs_equal_length(dfs):\n",
    "    # store all the date values from all the dataframes in a single list, then keep only the unique values\n",
    "    dates = []\n",
    "    for i in range(len(dfs)):\n",
    "        dates.extend(dfs[i]['Date'])\n",
    "    dates = list(set(dates))\n",
    "    print(\"Number of unique dates: \", len(dates))\n",
    "    # print dates one in each line\n",
    "    for date in dates:\n",
    "        # if any datetime contains a time, remove the datetime\n",
    "        if len(str(date).split(' ')) > 1:\n",
    "            dates.remove(date)\n",
    "            continue\n",
    "    dates.sort()\n",
    "    \n",
    "    # Iterate over all the dataframes and for each date, if the date is not present in the dataframe, add a row with all values as 0\n",
    "    for i in range(len(dfs)):\n",
    "        for date in dates:\n",
    "            if date not in dfs[i]['Date'].values:\n",
    "                df = pd.DataFrame([[date, 0]], columns=dfs[i].columns)\n",
    "                dfs[i] = pd.concat([dfs[i], df], ignore_index=True)  \n",
    "        print(\"Shape of dataframe \", i, \" is: \", dfs[i].shape)\n",
    "        # sort the dataframe by Date\n",
    "        dfs[i] = dfs[i].sort_values(by='Date')\n",
    "        \n",
    "    \n",
    "    # remove null values from the dataframes\n",
    "    for df in dfs:\n",
    "        df['Affected'] = pd.to_numeric(df['Affected'], errors='coerce').fillna(0).astype(float)\n",
    "\n",
    "    return dfs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_excel(dfs, filenames, files_directory):\n",
    "    for i in range(len(dfs)):\n",
    "        dfs[i].to_excel(files_directory + filenames[i], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(data_read_directory, coordinates_filepath, data_write_directory):\n",
    "    dfs, coordinates, filenames = read_files_and_coordinates(data_read_directory, coordinates_filepath)\n",
    "    print(\"Data read successfully\")\n",
    "    print(\"Number of files read: \", len(dfs))\n",
    "    print(\"Number of coordinates read: \", len(coordinates))\n",
    "    dfs = make_dfs_equal_length(dfs)\n",
    "    write_to_excel(dfs, filenames, data_write_directory)\n",
    "    print(\"Data written successfully\")\n",
    "    return dfs, coordinates, filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file:  250 shojja.xlsx  at index:  0\n",
      "Reading file:  31 shojja.xlsx  at index:  1\n",
      "Reading file:  ad-din.xlsx  at index:  2\n",
      "Reading file:  aichi.xlsx  at index:  3\n",
      "Reading file:  Al manar.xlsx  at index:  4\n",
      "Reading file:  amz hospital.xlsx  at index:  5\n",
      "Reading file:  Anowar khan.xlsx  at index:  6\n",
      "Reading file:  Apollo.xlsx  at index:  7\n",
      "Reading file:  azgor ali.xlsx  at index:  8\n",
      "Reading file:  Bangladesh Medical College Hospital.xlsx  at index:  9\n",
      "Reading file:  BD Specialized hospital.xlsx  at index:  10\n",
      "Reading file:  BGB Hospital.xlsx  at index:  11\n",
      "Reading file:  BIRDEM.xlsx  at index:  12\n",
      "Reading file:  brb hospital.xlsx  at index:  13\n",
      "Reading file:  BSSMU.xlsx  at index:  14\n",
      "Reading file:  Comfort Nursing.xlsx  at index:  15\n",
      "Reading file:  Dedicated Covid-19 Hospital.xlsx  at index:  16\n",
      "Reading file:  Delta medical.xlsx  at index:  17\n",
      "Reading file:  Dhaka central.xlsx  at index:  18\n",
      "Reading file:  Dhaka healthcare.xlsx  at index:  19\n",
      "Reading file:  Dhaka Mahanagar Medical College.xlsx  at index:  20\n",
      "Reading file:  Dhaka Mahanagar Shishu Hospital.xlsx  at index:  21\n",
      "Reading file:  Dhaka Shishu Hospital.xlsx  at index:  22\n",
      "Reading file:  dmd central.xlsx  at index:  23\n",
      "Reading file:  Enam medical.xlsx  at index:  24\n",
      "Reading file:  Exim bank.xlsx  at index:  25\n",
      "Reading file:  farabi general.xlsx  at index:  26\n",
      "Reading file:  Govt. Kormochari Hospital.xlsx  at index:  27\n",
      "Reading file:  Green Life Hospital.xlsx  at index:  28\n",
      "Reading file:  h&h.xlsx  at index:  29\n",
      "Reading file:  hfrc.xlsx  at index:  30\n",
      "Reading file:  High Care Hospital.xlsx  at index:  31\n",
      "Reading file:  ibn sina.xlsx  at index:  32\n",
      "Reading file:  islami bank.xlsx  at index:  33\n",
      "Reading file:  Japan BD hospital.xlsx  at index:  34\n",
      "Reading file:  Life & care hospital.xlsx  at index:  35\n",
      "Reading file:  lstm_dmc.xlsx  at index:  36\n",
      "Reading file:  Medical college for women.xlsx  at index:  37\n",
      "Reading file:  Metropoliton medical.xlsx  at index:  38\n",
      "Reading file:  monowara hospital.xlsx  at index:  39\n",
      "Reading file:  police hospital.xlsx  at index:  40\n",
      "Reading file:  popular medical.xlsx  at index:  41\n",
      "Reading file:  Sajeda hospital.xlsx  at index:  42\n",
      "Reading file:  salauddin hospital.xlsx  at index:  43\n",
      "Reading file:  Shomkramok Byadhi Hospital.xlsx  at index:  44\n",
      "Reading file:  Shommilito Shamorik Hospital,Savar.xlsx  at index:  45\n",
      "Reading file:  Shommilito Shamorik Hospital.xlsx  at index:  46\n",
      "Reading file:  shomorita.xlsx  at index:  47\n",
      "Reading file:  Square.xlsx  at index:  48\n",
      "Reading file:  ssmc.xlsx  at index:  49\n",
      "Reading file:  united hospital.xlsx  at index:  50\n",
      "Reading file:  universal.xlsx  at index:  51\n",
      "Reading file:  Uttara adhunik.xlsx  at index:  52\n",
      "Reading file:  Uttara crescent.xlsx  at index:  53\n",
      "Data read successfully\n",
      "Number of files read:  54\n",
      "Number of coordinates read:  39\n",
      "Number of unique dates:  720\n",
      "Shape of dataframe  0  is:  (720, 2)\n",
      "Shape of dataframe  1  is:  (720, 2)\n",
      "Shape of dataframe  2  is:  (720, 2)\n",
      "Shape of dataframe  3  is:  (720, 2)\n",
      "Shape of dataframe  4  is:  (720, 2)\n",
      "Shape of dataframe  5  is:  (720, 2)\n",
      "Shape of dataframe  6  is:  (720, 2)\n",
      "Shape of dataframe  7  is:  (720, 2)\n",
      "Shape of dataframe  8  is:  (720, 2)\n",
      "Shape of dataframe  9  is:  (720, 2)\n",
      "Shape of dataframe  10  is:  (720, 2)\n",
      "Shape of dataframe  11  is:  (720, 2)\n",
      "Shape of dataframe  12  is:  (720, 2)\n",
      "Shape of dataframe  13  is:  (720, 2)\n",
      "Shape of dataframe  14  is:  (720, 2)\n",
      "Shape of dataframe  15  is:  (720, 2)\n",
      "Shape of dataframe  16  is:  (720, 2)\n",
      "Shape of dataframe  17  is:  (720, 2)\n",
      "Shape of dataframe  18  is:  (720, 2)\n",
      "Shape of dataframe  19  is:  (720, 2)\n",
      "Shape of dataframe  20  is:  (720, 2)\n",
      "Shape of dataframe  21  is:  (720, 2)\n",
      "Shape of dataframe  22  is:  (720, 2)\n",
      "Shape of dataframe  23  is:  (720, 2)\n",
      "Shape of dataframe  24  is:  (720, 2)\n",
      "Shape of dataframe  25  is:  (720, 2)\n",
      "Shape of dataframe  26  is:  (720, 2)\n",
      "Shape of dataframe  27  is:  (720, 2)\n",
      "Shape of dataframe  28  is:  (720, 2)\n",
      "Shape of dataframe  29  is:  (720, 2)\n",
      "Shape of dataframe  30  is:  (720, 2)\n",
      "Shape of dataframe  31  is:  (720, 2)\n",
      "Shape of dataframe  32  is:  (720, 2)\n",
      "Shape of dataframe  33  is:  (720, 2)\n",
      "Shape of dataframe  34  is:  (720, 2)\n",
      "Shape of dataframe  35  is:  (720, 2)\n",
      "Shape of dataframe  36  is:  (720, 2)\n",
      "Shape of dataframe  37  is:  (720, 2)\n",
      "Shape of dataframe  38  is:  (720, 2)\n",
      "Shape of dataframe  39  is:  (720, 2)\n",
      "Shape of dataframe  40  is:  (720, 2)\n",
      "Shape of dataframe  41  is:  (720, 2)\n",
      "Shape of dataframe  42  is:  (720, 2)\n",
      "Shape of dataframe  43  is:  (720, 2)\n",
      "Shape of dataframe  44  is:  (720, 2)\n",
      "Shape of dataframe  45  is:  (720, 2)\n",
      "Shape of dataframe  46  is:  (720, 2)\n",
      "Shape of dataframe  47  is:  (720, 2)\n",
      "Shape of dataframe  48  is:  (720, 2)\n",
      "Shape of dataframe  49  is:  (720, 2)\n",
      "Shape of dataframe  50  is:  (720, 2)\n",
      "Shape of dataframe  51  is:  (720, 2)\n",
      "Shape of dataframe  52  is:  (720, 2)\n",
      "Shape of dataframe  53  is:  (720, 2)\n",
      "Data written successfully\n"
     ]
    }
   ],
   "source": [
    "data_read_directory = \"../../Data/Processed data/\"\n",
    "coordinates_filepath = \"../../Data/coordinates.xlsx\"\n",
    "data_write_directory = \"../../Data/Hospital Dataset/\"\n",
    "\n",
    "dfs, coordinates, filenames = data_preprocessing(data_read_directory, coordinates_filepath, data_write_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty numpy array with the required shape\n",
    "timestep = dfs[0].shape[0]\n",
    "hospitals = len(dfs)\n",
    "affected_array = np.zeros((timestep, hospitals, 1))\n",
    "\n",
    "# Populate the numpy array with the 'Affected' values from each dataframe\n",
    "for i in range(hospitals):\n",
    "    affected_array[:, i, 0] = dfs[i]['Affected'].values\n",
    "\n",
    "# Save the numpy array to a .npy file\n",
    "np.save('../../Data/Hospitals_of_Dhaka.npy', affected_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split affected_array into training,val,test (75%,15%,10%)\n",
    "\n",
    "train_size = int(affected_array.shape[0] * 0.75)\n",
    "val_size = int(affected_array.shape[0] * 0.15)\n",
    "test_size = int(affected_array.shape[0] * 0.10)\n",
    "\n",
    "train_data = affected_array[:train_size]\n",
    "val_data = affected_array[train_size:train_size+val_size]\n",
    "test_data = affected_array[train_size+val_size:]\n",
    "\n",
    "np.save('../../Data/Hospitals_of_Dhaka_train.npy', train_data)\n",
    "np.save('../../Data/Hospitals_of_Dhaka_val.npy', val_data)\n",
    "np.save('../../Data/Hospitals_of_Dhaka_test.npy', test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dates in a separate excel file\n",
    "dates = dfs[0]['Date'].values\n",
    "dates = np.array(dates)\n",
    "dates = dates.reshape((dates.shape[0], 1))\n",
    "dates_df = pd.DataFrame(dates, columns=['Date'])\n",
    "dates_df.to_excel('../../dates.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
